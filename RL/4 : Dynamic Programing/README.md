### Chapter 4 : Dynamic Programming

---

- Dynamic Programming


      A collection of algorithms that can be used to compute optimal policies given a perfect model (MDP)

      # Limitation in utility
        1) A perfect model; p(s', r | s, a), is needed
        2) great computational expense

      # Typical assumption in DP
        1) Perfect Model is given.
        2) finite MDP



- confusing MDP names


      [1] Discrete MDP (finite MDP) vs Continuous MDP (infinite MDP)

        Discrete MDP => the state, action, and reward sets are finite (discrete)
        Continuous MDP => the state, action, and reward are infinite (continuous)

      [2] Deterministic MDP vs Stochastic MDP
  
        Deterministic MDP => deterministic policy
        Stochastic MDP => stochastic policy 
